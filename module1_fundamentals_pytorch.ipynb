{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPg0YICdCgLHJ28ewh3FjPU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sonuthahreen/coding-part-of-pytorch/blob/main/module1_fundamentals_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "resource:https://www.youtube.com/watch?v=V_xro1bcAuA"
      ],
      "metadata": {
        "id": "Toerl2eC1O0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"lets start the joruney with BIRBLE AI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gf1MgSy0hwhv",
        "outputId": "11255c7c-2c50-44c2-85e9-bac6c3084990"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lets start the joruney with BIRBLE AI\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6DE3iJiiTG6",
        "outputId": "f2044bd4-aac3-4202-b670-e214e93fdea6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  8 16:25:49 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b_4vbwanitkO",
        "outputId": "52fdec66-ff05-463b-a41c-0a4e71b33fd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.1.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwB0nE3nkrz0",
        "outputId": "82db5682-5511-448b-abed-537894a3444e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Feb  8 16:37:14 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##INTRODUCTION TO TENSOR\n",
        "**CREATING TENSORS**\n",
        "pytorch tensors are created using 'torch.tensor()'\n",
        "\n"
      ],
      "metadata": {
        "id": "Kk73NOeRlvSP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scalar=torch.tensor(7)\n",
        "scalar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38-M3lDAnU6S",
        "outputId": "fee0b5b1-5d06-4e9a-b1ef-4a73413e832f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scalar.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX4pj2b2nhHU",
        "outputId": "fb937228-0705-475a-aa38-ceb03aa53ed2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#get tensor back as python int\n",
        "scalar.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWhzmmC-nk2a",
        "outputId": "99dcdbe2-a0c3-4ffc-88f3-d0002d7fc1b5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vector\n",
        "vector=torch.tensor([7,7])\n",
        "vector"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZWQdjhInsfq",
        "outputId": "f94338ce-355e-474a-ab6d-83c4aff07cb0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vector define as usually have magnitude and direction"
      ],
      "metadata": {
        "id": "Yd1_QpUfn7Ef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDKcybf5oGiB",
        "outputId": "bec01414-883b-4fb6-bd34-e48e6342c286"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vector.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq-Wu9TtoLSD",
        "outputId": "e62586b4-a1ea-42cd-8be7-4021a4994758"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creation of MATRIX\n",
        "matrix=torch.tensor([[7,8],[9,10]])\n",
        "matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PRMIYMoO-L",
        "outputId": "733e1bb7-4261-4d87-d56d-043d545a2e1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IME9D-Oiojr7",
        "outputId": "06d80aef-8156-463f-bce0-7a56fa04f1c0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXkYyAjxom0y",
        "outputId": "0360105a-6dfa-45bc-8d9c-b53b02efde78"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LA1FQanBompw",
        "outputId": "f7939e94-da9e-40aa-a090-6fd02f6a33c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Tensor\n",
        "TENSOR=torch.tensor([[[1,2,3],[3,4,5],[6,7,8]]])\n",
        "TENSOR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SiMMQLAomnU",
        "outputId": "c8a98ef3-e364-4b20-8b50-68517da31b73"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 4, 5],\n",
              "         [6, 7, 8]]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KxrrD9nAomlF",
        "outputId": "6c6a5928-36f7-4aa5-c7a6-f1f783f40a90"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TENSOR.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nae5jDVepBsb",
        "outputId": "4b2b8d61-ce26-42ba-f255-e26d73006f88"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Random Tensors\n",
        "why random tensors?\n",
        "\n",
        "Random Tensors are important because the way many neural networks learns is they start with tensors full of random numbers and then adjust those random numbers to better represent the data\n",
        "start with random numbers ->look at data -> update random numbers -> look at the data ->update random numbers"
      ],
      "metadata": {
        "id": "hYKHZiMtq32R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a random tensor of size (3,4)#practice\n",
        "random_tensor=torch.rand(30,30)\n",
        "random_tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3p7YOxbHroRa",
        "outputId": "ff6253a2-0f9e-4fc8-c943-14426a99640c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.9988e-01, 8.9506e-01, 4.5341e-01, 1.6763e-01, 4.3803e-01, 9.8105e-01,\n",
              "         4.1389e-01, 1.9590e-01, 5.5549e-01, 8.0917e-01, 9.4275e-01, 1.7622e-01,\n",
              "         6.6054e-01, 9.2125e-02, 7.1536e-01, 6.8763e-01, 7.8527e-01, 7.5123e-01,\n",
              "         8.8107e-01, 2.5435e-01, 6.0708e-01, 6.8827e-01, 3.0037e-01, 6.2505e-01,\n",
              "         5.2560e-01, 1.7654e-01, 7.2473e-01, 4.9500e-01, 7.6655e-01, 3.3049e-01],\n",
              "        [2.5099e-01, 2.8646e-01, 3.1247e-01, 8.5567e-02, 3.8446e-01, 2.7923e-01,\n",
              "         4.3674e-01, 1.7944e-02, 7.8164e-01, 6.5335e-02, 6.4047e-01, 2.6574e-01,\n",
              "         5.5575e-01, 2.0213e-01, 4.9421e-01, 5.2114e-01, 8.1278e-01, 9.3961e-01,\n",
              "         4.3596e-01, 1.3362e-01, 3.0770e-01, 9.3124e-01, 7.8229e-01, 2.7051e-01,\n",
              "         6.1654e-01, 7.3805e-01, 6.5766e-01, 6.7684e-01, 6.7309e-01, 7.9082e-01],\n",
              "        [6.0187e-01, 2.5093e-01, 6.1785e-01, 7.3076e-01, 5.9613e-01, 4.8587e-01,\n",
              "         2.5980e-01, 3.7018e-02, 2.3867e-01, 3.4697e-01, 5.0313e-01, 3.9782e-01,\n",
              "         9.9942e-01, 1.0796e-01, 7.6670e-01, 5.2232e-01, 1.5965e-01, 9.4104e-01,\n",
              "         6.8464e-01, 7.9406e-01, 9.9623e-01, 8.9856e-01, 7.1103e-01, 7.1330e-01,\n",
              "         9.8496e-01, 6.3543e-01, 9.1511e-01, 6.2463e-01, 9.1946e-01, 6.3714e-01],\n",
              "        [5.9261e-02, 3.0176e-01, 7.0790e-01, 3.8150e-01, 8.8940e-01, 6.6998e-01,\n",
              "         3.9074e-01, 9.3493e-01, 4.1895e-01, 8.2143e-01, 6.0630e-01, 9.7024e-02,\n",
              "         8.1170e-01, 6.2306e-02, 2.2156e-01, 2.1070e-01, 8.9079e-01, 6.1025e-01,\n",
              "         4.1943e-01, 7.1494e-01, 5.0410e-01, 8.0197e-01, 4.2685e-01, 5.9963e-01,\n",
              "         4.5341e-01, 7.1277e-01, 2.0669e-01, 1.6660e-02, 2.9152e-01, 4.0122e-03],\n",
              "        [2.5981e-01, 1.6003e-01, 8.3470e-01, 8.2945e-01, 1.7974e-02, 1.7784e-01,\n",
              "         3.3556e-01, 4.7345e-01, 3.0805e-01, 6.1413e-01, 5.0245e-01, 6.8499e-02,\n",
              "         6.6993e-01, 9.8044e-01, 7.5308e-01, 6.3421e-01, 1.1663e-01, 2.3452e-01,\n",
              "         2.9474e-01, 3.8906e-01, 1.1372e-02, 1.7209e-01, 8.8140e-01, 9.1809e-01,\n",
              "         9.3710e-02, 2.3505e-01, 9.3271e-01, 7.6725e-01, 9.8494e-01, 1.6687e-01],\n",
              "        [2.5534e-01, 5.0617e-01, 9.2272e-01, 4.9529e-01, 5.3912e-01, 7.6466e-01,\n",
              "         9.5672e-02, 8.5744e-01, 4.0108e-01, 3.9738e-01, 3.3459e-01, 5.5042e-01,\n",
              "         8.2000e-01, 7.5522e-01, 7.6562e-01, 8.6001e-01, 8.1059e-01, 2.0223e-01,\n",
              "         3.0265e-01, 9.4571e-01, 1.2282e-01, 5.3738e-01, 1.1042e-01, 8.4567e-01,\n",
              "         2.8510e-01, 6.4832e-01, 7.6492e-01, 5.6873e-01, 6.7917e-01, 8.0749e-01],\n",
              "        [5.4974e-01, 5.9987e-01, 2.5144e-01, 7.8014e-01, 6.7035e-01, 4.0500e-01,\n",
              "         7.1474e-01, 2.5920e-01, 7.0685e-01, 2.0750e-01, 1.6594e-01, 7.6779e-01,\n",
              "         2.3264e-02, 9.1557e-01, 4.3108e-01, 9.4459e-01, 8.8442e-01, 7.2620e-02,\n",
              "         7.7277e-02, 7.5533e-01, 4.4513e-02, 2.7557e-01, 1.6604e-01, 4.6475e-01,\n",
              "         4.0760e-01, 3.7196e-01, 6.0649e-01, 7.3094e-01, 6.2578e-01, 2.2898e-01],\n",
              "        [3.6838e-01, 8.2971e-01, 2.4684e-01, 9.7787e-01, 3.9836e-01, 3.5154e-01,\n",
              "         2.5464e-01, 8.1295e-01, 9.9926e-01, 2.6717e-01, 8.5025e-01, 5.6525e-01,\n",
              "         9.0168e-01, 6.8275e-01, 2.9650e-01, 9.8076e-01, 2.3553e-02, 2.1589e-01,\n",
              "         2.6929e-01, 4.3898e-01, 9.3594e-01, 6.1983e-01, 6.9618e-01, 2.6992e-01,\n",
              "         1.9704e-01, 2.8469e-01, 2.1971e-01, 3.6530e-01, 9.2688e-01, 6.5859e-01],\n",
              "        [3.5759e-02, 1.0007e-01, 9.9380e-01, 6.9620e-02, 4.7253e-01, 1.6021e-01,\n",
              "         4.0506e-01, 1.6718e-01, 6.5523e-01, 4.2454e-01, 7.8883e-01, 7.5191e-01,\n",
              "         8.9019e-01, 4.4472e-01, 6.5458e-01, 2.4711e-01, 7.4638e-01, 3.9140e-01,\n",
              "         9.9043e-02, 9.7878e-01, 2.0095e-01, 3.8686e-01, 2.6635e-01, 2.7634e-01,\n",
              "         9.9160e-02, 2.1881e-02, 1.2958e-01, 5.9969e-02, 4.7825e-01, 7.6878e-01],\n",
              "        [3.3335e-01, 4.0169e-01, 6.5036e-01, 9.9905e-01, 1.9130e-01, 7.6876e-01,\n",
              "         7.5272e-01, 1.9244e-01, 2.7537e-02, 8.5453e-01, 6.6684e-01, 4.9703e-01,\n",
              "         9.0711e-01, 3.9063e-01, 8.4192e-01, 8.3515e-01, 7.9678e-01, 9.7126e-01,\n",
              "         5.6936e-01, 1.6168e-02, 3.4989e-01, 5.8659e-01, 9.5083e-02, 3.4091e-01,\n",
              "         7.9674e-01, 9.3113e-01, 6.7505e-01, 6.1192e-02, 7.8745e-01, 3.2414e-02],\n",
              "        [1.5593e-01, 6.1714e-01, 8.1018e-01, 9.9819e-01, 3.9363e-01, 1.4072e-01,\n",
              "         2.3562e-01, 7.4065e-01, 7.3793e-01, 6.9976e-01, 3.6518e-01, 1.9470e-01,\n",
              "         2.1483e-01, 5.1703e-01, 1.9829e-01, 6.3273e-01, 1.1345e-03, 7.3978e-01,\n",
              "         8.9172e-01, 6.2390e-01, 4.0037e-01, 5.3012e-01, 5.9186e-01, 6.0837e-01,\n",
              "         4.0910e-01, 9.5927e-01, 7.2110e-01, 4.1441e-01, 4.0675e-01, 6.6265e-01],\n",
              "        [6.3618e-01, 6.7816e-01, 8.1802e-01, 6.4092e-01, 5.1811e-01, 8.6341e-01,\n",
              "         7.6695e-01, 1.7384e-01, 4.9486e-01, 3.9587e-01, 6.6201e-01, 6.2104e-01,\n",
              "         7.1913e-01, 5.5897e-01, 3.6667e-01, 7.1400e-01, 1.2195e-01, 8.8473e-01,\n",
              "         9.5168e-02, 2.0781e-01, 9.3225e-01, 2.4450e-01, 7.9910e-01, 7.8369e-01,\n",
              "         6.7402e-01, 3.5486e-02, 2.3390e-01, 9.5861e-01, 1.7249e-01, 8.3201e-01],\n",
              "        [3.9157e-01, 7.1106e-02, 9.9087e-01, 4.7295e-01, 4.7500e-01, 2.0338e-01,\n",
              "         6.1858e-01, 5.6691e-01, 6.0940e-01, 8.1257e-01, 7.7642e-01, 7.6679e-01,\n",
              "         6.5166e-01, 3.6951e-01, 5.5642e-01, 3.6774e-01, 1.9107e-01, 6.6510e-01,\n",
              "         7.4144e-01, 1.5291e-01, 7.8737e-01, 1.8925e-01, 3.2445e-01, 1.0970e-01,\n",
              "         2.1164e-01, 4.1882e-01, 1.1126e-02, 3.0803e-01, 6.6926e-01, 9.0453e-01],\n",
              "        [9.1882e-01, 2.1861e-01, 8.9023e-01, 1.3565e-01, 1.3297e-01, 8.1255e-01,\n",
              "         6.3564e-01, 4.1217e-01, 4.3827e-01, 3.7951e-01, 1.0855e-02, 1.5380e-01,\n",
              "         7.7978e-01, 4.5806e-04, 9.4797e-02, 6.9432e-01, 3.0909e-01, 6.7683e-02,\n",
              "         9.3099e-01, 2.2531e-01, 1.4044e-01, 5.9909e-01, 5.1888e-01, 2.7764e-01,\n",
              "         7.1419e-02, 6.4506e-01, 4.2038e-01, 5.2163e-01, 7.4156e-01, 8.3293e-01],\n",
              "        [7.4478e-01, 5.2638e-01, 4.6884e-01, 4.6211e-01, 3.5680e-01, 9.1563e-01,\n",
              "         2.0171e-01, 4.9048e-01, 2.3312e-01, 1.6507e-01, 6.9763e-02, 3.3569e-01,\n",
              "         9.4379e-01, 5.5960e-01, 3.2007e-03, 5.7293e-01, 7.8364e-01, 6.4980e-01,\n",
              "         8.3708e-01, 4.8103e-01, 6.9433e-01, 1.1918e-01, 4.7042e-01, 8.6449e-01,\n",
              "         9.0762e-01, 4.9477e-01, 8.9720e-01, 4.0234e-01, 7.9981e-01, 2.9789e-01],\n",
              "        [6.0047e-01, 2.7054e-01, 8.7049e-01, 9.5219e-01, 3.3990e-01, 1.3903e-01,\n",
              "         5.9333e-01, 4.2154e-01, 6.7677e-01, 8.0638e-01, 8.3439e-01, 7.6670e-01,\n",
              "         9.2752e-01, 8.6007e-01, 9.6998e-01, 2.7043e-01, 6.7399e-03, 1.0906e-01,\n",
              "         3.0277e-01, 8.3671e-01, 8.4387e-01, 5.2481e-01, 1.9243e-01, 8.3891e-01,\n",
              "         7.4597e-03, 7.8817e-01, 9.5971e-01, 3.2888e-01, 3.4826e-01, 6.5751e-01],\n",
              "        [5.4975e-02, 8.0248e-01, 5.3261e-02, 1.5848e-01, 2.3617e-01, 1.9820e-01,\n",
              "         8.6411e-01, 5.1424e-01, 1.2343e-01, 7.9981e-01, 6.5220e-01, 8.1454e-01,\n",
              "         2.8111e-01, 7.3881e-01, 9.5675e-01, 6.8386e-01, 3.8413e-01, 8.7971e-01,\n",
              "         5.1802e-01, 4.2050e-01, 9.8835e-01, 6.6505e-01, 2.6097e-01, 2.6518e-01,\n",
              "         7.0272e-01, 9.0269e-01, 6.5860e-01, 9.4811e-01, 5.8286e-01, 1.4717e-01],\n",
              "        [9.1197e-01, 4.7036e-01, 9.9015e-02, 6.5488e-01, 4.4208e-01, 1.6264e-02,\n",
              "         9.4988e-01, 5.0030e-01, 7.9582e-01, 2.8347e-01, 7.2540e-01, 9.0820e-01,\n",
              "         9.3429e-01, 2.1453e-01, 5.4669e-02, 6.8545e-01, 9.6776e-01, 3.7023e-01,\n",
              "         3.9333e-01, 2.3345e-01, 9.4060e-01, 3.1379e-01, 5.0272e-01, 2.2627e-01,\n",
              "         7.8393e-01, 9.3370e-01, 4.1086e-01, 2.1638e-01, 9.6099e-01, 3.4962e-01],\n",
              "        [6.0717e-01, 9.7111e-01, 6.9409e-01, 4.4104e-01, 6.9684e-01, 5.5055e-01,\n",
              "         3.6493e-01, 4.8287e-01, 6.8875e-01, 1.1765e-01, 6.0026e-01, 9.8369e-01,\n",
              "         5.7260e-01, 8.9850e-02, 8.4691e-01, 3.1156e-01, 4.6016e-01, 8.5789e-01,\n",
              "         7.3599e-01, 6.4663e-01, 9.0465e-01, 4.9415e-01, 6.1203e-01, 8.8298e-02,\n",
              "         6.7423e-02, 4.6642e-01, 9.0995e-01, 7.8643e-02, 6.6496e-01, 1.2983e-01],\n",
              "        [1.3384e-01, 1.2768e-01, 8.4027e-01, 3.2904e-01, 7.8692e-01, 7.8008e-01,\n",
              "         3.2563e-01, 2.5937e-01, 3.6742e-01, 5.0936e-01, 4.8674e-01, 1.9283e-01,\n",
              "         8.5880e-01, 5.6023e-01, 6.7039e-01, 1.1917e-01, 9.1327e-01, 6.6476e-01,\n",
              "         3.4856e-01, 4.7550e-01, 1.3936e-01, 3.9091e-01, 4.5159e-01, 8.9121e-01,\n",
              "         1.4126e-01, 6.7866e-01, 4.6416e-01, 6.3750e-01, 3.1431e-01, 4.1268e-02],\n",
              "        [7.4053e-01, 5.3127e-01, 4.0182e-01, 2.4413e-01, 8.7400e-01, 2.6909e-01,\n",
              "         1.3460e-01, 7.8432e-01, 5.7347e-01, 2.6384e-01, 7.8509e-01, 7.1894e-01,\n",
              "         9.8371e-01, 9.7758e-01, 8.4988e-01, 3.4130e-01, 7.7766e-01, 6.5891e-01,\n",
              "         3.4209e-01, 5.1693e-01, 4.0936e-01, 9.3362e-01, 6.1615e-01, 4.3574e-01,\n",
              "         6.5277e-01, 8.5075e-01, 3.7571e-01, 9.2644e-01, 1.1734e-01, 3.0129e-01],\n",
              "        [4.7897e-01, 1.2680e-01, 8.2565e-02, 7.0844e-01, 4.5644e-01, 9.4516e-03,\n",
              "         5.3559e-01, 9.5418e-01, 7.8017e-01, 3.9368e-01, 1.0373e-01, 6.9181e-01,\n",
              "         4.1728e-01, 7.5035e-01, 9.6668e-01, 3.9987e-01, 9.6602e-01, 5.2729e-01,\n",
              "         7.2046e-01, 9.1292e-01, 9.4291e-02, 5.5779e-01, 9.7028e-01, 1.1029e-01,\n",
              "         3.4938e-02, 8.9365e-01, 6.0670e-01, 6.3265e-01, 4.8677e-01, 2.1932e-01],\n",
              "        [5.8475e-01, 3.1951e-01, 7.0442e-01, 1.9014e-01, 8.5898e-01, 7.8708e-01,\n",
              "         8.3407e-01, 1.5404e-01, 5.8669e-01, 7.9853e-01, 4.8954e-01, 1.2604e-01,\n",
              "         1.1310e-01, 8.1875e-01, 9.4956e-01, 5.7335e-01, 9.0675e-01, 4.6315e-01,\n",
              "         3.7199e-02, 3.0452e-01, 8.9750e-01, 3.6119e-01, 1.0135e-01, 2.8880e-01,\n",
              "         1.4928e-01, 9.1337e-01, 3.1414e-01, 1.1300e-01, 4.5592e-01, 9.1960e-01],\n",
              "        [9.4146e-02, 2.4033e-01, 6.2959e-01, 4.5564e-01, 6.5894e-02, 5.7149e-01,\n",
              "         9.3847e-01, 3.6824e-01, 5.7924e-01, 6.1345e-01, 5.0449e-01, 8.2895e-01,\n",
              "         1.5614e-01, 5.7239e-02, 6.9101e-01, 3.3874e-01, 9.0055e-01, 9.4637e-01,\n",
              "         6.0543e-01, 1.1574e-01, 8.3551e-01, 4.3069e-01, 5.9544e-01, 9.2861e-01,\n",
              "         3.6758e-01, 7.2724e-01, 8.6756e-01, 8.8808e-01, 5.8555e-01, 4.1340e-01],\n",
              "        [4.7264e-01, 5.0398e-01, 6.2870e-01, 4.8763e-01, 5.5308e-01, 3.6350e-01,\n",
              "         6.0795e-01, 4.2294e-01, 1.5238e-01, 6.6850e-01, 9.3938e-01, 1.3281e-01,\n",
              "         3.3546e-01, 8.6307e-01, 5.3863e-01, 1.2516e-01, 9.8170e-01, 3.2250e-01,\n",
              "         9.6149e-01, 3.7110e-01, 1.3977e-02, 5.3133e-01, 9.7964e-01, 6.8385e-01,\n",
              "         8.3716e-01, 7.2275e-01, 2.7097e-01, 9.1478e-01, 2.7407e-01, 9.0936e-01],\n",
              "        [7.0976e-01, 2.5154e-01, 7.8932e-01, 2.7737e-01, 2.7025e-01, 6.9837e-01,\n",
              "         3.3036e-01, 5.0826e-02, 8.2898e-01, 9.0710e-01, 1.9658e-01, 1.0279e-02,\n",
              "         5.6453e-01, 8.7451e-01, 4.2245e-01, 6.9838e-01, 2.2033e-01, 7.0162e-01,\n",
              "         6.6995e-01, 3.5030e-01, 6.6286e-01, 5.6252e-01, 8.4134e-01, 9.5618e-01,\n",
              "         1.1582e-01, 5.0028e-01, 8.7987e-01, 6.9386e-01, 7.9694e-01, 4.4393e-01],\n",
              "        [8.3689e-01, 7.7866e-01, 3.5652e-01, 9.3155e-01, 5.0683e-01, 1.5170e-01,\n",
              "         6.4241e-01, 2.8474e-01, 6.8366e-01, 5.4034e-01, 9.9147e-01, 3.3903e-01,\n",
              "         5.7523e-01, 5.8174e-01, 8.0136e-01, 1.9845e-01, 5.6222e-01, 9.5249e-01,\n",
              "         1.7420e-01, 3.4283e-01, 7.9539e-01, 5.4288e-01, 5.1145e-01, 6.8446e-01,\n",
              "         3.1156e-01, 1.9130e-01, 5.8124e-01, 9.2014e-01, 4.5153e-01, 8.0135e-02],\n",
              "        [2.2433e-02, 3.8309e-01, 7.2476e-01, 6.5317e-01, 6.6237e-01, 6.6999e-01,\n",
              "         1.3139e-01, 3.6538e-01, 3.1866e-01, 3.1868e-01, 7.2753e-01, 8.6235e-01,\n",
              "         1.3054e-01, 7.5728e-01, 4.7454e-01, 8.3631e-01, 2.2665e-01, 9.8428e-01,\n",
              "         8.8800e-01, 5.0059e-01, 7.6464e-01, 8.3588e-01, 3.5737e-01, 7.6771e-05,\n",
              "         3.7671e-01, 1.8247e-01, 3.2753e-01, 7.9212e-01, 1.2189e-01, 6.0862e-01],\n",
              "        [6.1992e-01, 1.6443e-01, 1.8406e-01, 7.5207e-01, 8.8744e-01, 9.4214e-01,\n",
              "         6.4379e-01, 5.0030e-01, 8.6695e-01, 9.8978e-01, 6.5989e-02, 2.8566e-01,\n",
              "         8.5810e-01, 1.6630e-01, 2.9345e-01, 8.8731e-01, 2.6289e-01, 7.9399e-01,\n",
              "         5.4778e-01, 8.3530e-01, 8.6150e-01, 6.9222e-01, 8.3139e-01, 9.7908e-01,\n",
              "         1.6534e-03, 2.0087e-01, 8.2249e-01, 9.2087e-01, 2.2294e-01, 9.9192e-01],\n",
              "        [7.2803e-01, 3.9912e-01, 9.1495e-02, 5.5344e-01, 6.9270e-02, 4.8339e-01,\n",
              "         9.3777e-01, 2.1054e-01, 2.6050e-01, 6.4544e-01, 7.9252e-01, 8.8330e-01,\n",
              "         9.1440e-01, 7.3427e-01, 4.7473e-01, 2.5525e-01, 7.0527e-03, 8.1947e-01,\n",
              "         6.7288e-01, 5.7876e-01, 3.3352e-01, 3.4745e-01, 7.2892e-01, 1.0559e-01,\n",
              "         3.0472e-01, 6.9868e-01, 7.2752e-02, 9.9846e-01, 3.4927e-01, 8.0953e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "random_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A52YScEGsGaW",
        "outputId": "dcc80077-96de-4771-8a2a-f44b5beb5016"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a random tensor with similar shape to an image\n",
        "random_image_size_tensor=torch.rand(size=(224,224,3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyCWly8hsWig",
        "outputId": "ce902731-db64-4682-9e66-a05fcf0d2ebb"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor of all zeros\n",
        "zeros=torch.zeros(size=(3,4))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DEugf7Fytq1K",
        "outputId": "ea19eedd-4a7d-47a2-a223-d97a1e020876"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor of all ones\n",
        "ones=torch.ones(size=(3,4))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYWdeGqBubVG",
        "outputId": "62c0c802-0460-4f6f-892f-6f7c29f7e140"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ones.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSHYF12-uma-",
        "outputId": "3b82948e-0926-41e8-b531-7242440dd439"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#practice\n",
        "#creating a tensor of all zeros\n",
        "zeros=torch.zeros(size=(10,3))\n",
        "zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TbKiCu0urtE",
        "outputId": "28eb2379-d445-4a47-c18f-a7c2a1ca66fb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating a tensor of all ones\n",
        "ones=torch.ones(size=(3,10))\n",
        "ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZUkm7xLu4EE",
        "outputId": "813189bc-230b-4c5f-87ba-ac511eb432c1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
              "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "creating a range of tensors and tensors-like"
      ],
      "metadata": {
        "id": "PQzysJV3u__R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#use torch.range()\n",
        "one_to_ten=torch.arange(start=1,end=11,step=1)\n",
        "one_to_ten"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwzdAmWsu_JQ",
        "outputId": "f9493edd-004d-4a3c-ea57-80947318246c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating tensors like\n",
        "ten_zeros=torch.zeros_like(input=one_to_ten)\n",
        "ten_zeros"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EtY0hoivus2",
        "outputId": "854b5b4e-37ac-4478-cb6a-8efecef4167c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dealing with tensor datatpes"
      ],
      "metadata": {
        "id": "Co_5a52BwZyj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "here are many different tensor datatypes available in PyTorch.\n",
        "\n",
        "Some are specific for CPU and some are better for GPU.\n",
        "\n",
        "Getting to know which is which can take some time.\n",
        "\n",
        "Generally if you see torch.cuda anywhere, the tensor is being used for GPU (since Nvidia GPUs use a computing toolkit called CUDA).\n",
        "\n",
        "The most common type (and generally the default) is torch.float32 or torch.float.\n",
        "\n",
        "This is referred to as \"32-bit floating point\".\n",
        "\n",
        "But there's also 16-bit floating point (torch.float16 or torch.half) and 64-bit floating point (torch.float64 or torch.double).\n",
        "\n",
        "And to confuse things even more there's also 8-bit, 16-bit, 32-bit and 64-bit integers.\n",
        "\n",
        "Plus more!\n",
        "\n",
        "Note: An integer is a flat round number like 7 whereas a float has a decimal 7.0.\n",
        "\n",
        "The reason for all of these is to do with precision in computing.\n",
        "\n",
        "Precision is the amount of detail used to describe a number.\n",
        "\n",
        "The higher the precision value (8, 16, 32), the more detail and hence data used to express a number.\n",
        "\n",
        "This matters in deep learning and numerical computing because you're making so many operations, the more detail you have to calculate on, the more compute you have to use.\n",
        "\n",
        "So lower precision datatypes are generally faster to compute on but sacrifice some performance on evaluation metrics like accuracy (faster to compute but less accurate)."
      ],
      "metadata": {
        "id": "DQ5jzQPyyiZ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Float 32 tensor\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None,\n",
        "                               device=None,\n",
        "                               requires_grad=False)\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yfq_to50wiKy",
        "outputId": "b9088747-5ec8-450b-b635-a1cd2d393a19"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "float_32_tensor.dtype"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYwct97yy-ES",
        "outputId": "5e4a6d45-cdf0-4218-9882-baa3e10c1ddf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**:Tensor datatypes is one of the 3big errors we will run into with pytorch and deep learning(DL)\n",
        "1.Tensors not right datatype\n",
        "2.tensors not right shape\n",
        "3.Tenors not on the right device"
      ],
      "metadata": {
        "id": "mLo7AHvbzUlN"
      }
    }
  ]
}